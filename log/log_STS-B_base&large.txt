INFO:root:03:07:12 Namespace(accumulate=None, batch_size=32, bert_dataset='book_corpus_wiki_en_uncased', bert_model='bert_12_768_12', calib_mode='customize', deploy=False, dev_batch_size=8, dtype='float32', early_stop=None, epochs=5, epsilon=1e-06, gpu=0, log_interval=10, lr=2e-05, max_len=128, model_parameters=None, model_prefix=None, num_calib_batches=5, only_calibration=False, only_inference=False, optimizer='bertadam', output_dir='./output_dir', pretrained_bert_parameters=None, quantized_dtype='auto', round_to=None, seed=24, task_name='STS-B', training_steps=None, warmup_ratio=0.1)
INFO:root:03:07:16 processing dataset...
INFO:root:03:07:27 Now we are doing BERT classification training on gpu(0)!
INFO:root:03:07:27 training steps=898
INFO:root:03:07:30 [Epoch 1 Batch 10/186] loss=3.6135, lr=0.0000020, metrics:pearsonr:0.0529
INFO:root:03:07:32 [Epoch 1 Batch 20/186] loss=2.6019, lr=0.0000043, metrics:pearsonr:0.0409
INFO:root:03:07:34 [Epoch 1 Batch 30/186] loss=2.1061, lr=0.0000065, metrics:pearsonr:0.0544
INFO:root:03:07:37 [Epoch 1 Batch 40/186] loss=1.1362, lr=0.0000088, metrics:pearsonr:0.0136
INFO:root:03:07:39 [Epoch 1 Batch 50/186] loss=0.6695, lr=0.0000110, metrics:pearsonr:0.0878
INFO:root:03:07:41 [Epoch 1 Batch 60/186] loss=0.5808, lr=0.0000133, metrics:pearsonr:0.1654
INFO:root:03:07:43 [Epoch 1 Batch 70/186] loss=0.4845, lr=0.0000155, metrics:pearsonr:0.2568
INFO:root:03:07:45 [Epoch 1 Batch 80/186] loss=0.4728, lr=0.0000178, metrics:pearsonr:0.2953
INFO:root:03:07:48 [Epoch 1 Batch 90/186] loss=0.4255, lr=0.0000200, metrics:pearsonr:0.3569
INFO:root:03:07:50 [Epoch 1 Batch 100/186] loss=0.4061, lr=0.0000198, metrics:pearsonr:0.3916
INFO:root:03:07:52 [Epoch 1 Batch 110/186] loss=0.3404, lr=0.0000195, metrics:pearsonr:0.4348
INFO:root:03:07:54 [Epoch 1 Batch 120/186] loss=0.4525, lr=0.0000193, metrics:pearsonr:0.4643
INFO:root:03:07:56 [Epoch 1 Batch 130/186] loss=0.3192, lr=0.0000190, metrics:pearsonr:0.4837
INFO:root:03:07:58 [Epoch 1 Batch 140/186] loss=0.3692, lr=0.0000188, metrics:pearsonr:0.5071
INFO:root:03:08:01 [Epoch 1 Batch 150/186] loss=0.3076, lr=0.0000185, metrics:pearsonr:0.5272
INFO:root:03:08:03 [Epoch 1 Batch 160/186] loss=0.3159, lr=0.0000183, metrics:pearsonr:0.5494
INFO:root:03:08:06 [Epoch 1 Batch 170/186] loss=0.3080, lr=0.0000180, metrics:pearsonr:0.5648
INFO:root:03:08:08 [Epoch 1 Batch 180/186] loss=0.2861, lr=0.0000178, metrics:pearsonr:0.5802
INFO:root:03:08:09 Now we are doing evaluation on dev with gpu(0).
INFO:root:03:08:10 [Batch 10/188] loss=0.1820, metrics:pearsonr:0.9298
INFO:root:03:08:10 [Batch 20/188] loss=0.2445, metrics:pearsonr:0.9263
INFO:root:03:08:10 [Batch 30/188] loss=0.1855, metrics:pearsonr:0.9258
INFO:root:03:08:11 [Batch 40/188] loss=0.2564, metrics:pearsonr:0.9211
INFO:root:03:08:11 [Batch 50/188] loss=0.2846, metrics:pearsonr:0.9151
INFO:root:03:08:11 [Batch 60/188] loss=0.2024, metrics:pearsonr:0.9159
INFO:root:03:08:11 [Batch 70/188] loss=0.3964, metrics:pearsonr:0.9061
INFO:root:03:08:12 [Batch 80/188] loss=0.3331, metrics:pearsonr:0.9021
INFO:root:03:08:12 [Batch 90/188] loss=0.4891, metrics:pearsonr:0.8886
INFO:root:03:08:13 [Batch 100/188] loss=0.2556, metrics:pearsonr:0.8868
INFO:root:03:08:13 [Batch 110/188] loss=0.2860, metrics:pearsonr:0.8813
INFO:root:03:08:13 [Batch 120/188] loss=0.3317, metrics:pearsonr:0.8775
INFO:root:03:08:14 [Batch 130/188] loss=0.2457, metrics:pearsonr:0.8774
INFO:root:03:08:14 [Batch 140/188] loss=0.1812, metrics:pearsonr:0.8804
INFO:root:03:08:15 [Batch 150/188] loss=0.1622, metrics:pearsonr:0.8821
INFO:root:03:08:15 [Batch 160/188] loss=0.2581, metrics:pearsonr:0.8808
INFO:root:03:08:15 [Batch 170/188] loss=0.3018, metrics:pearsonr:0.8785
INFO:root:03:08:16 [Batch 180/188] loss=0.2578, metrics:pearsonr:0.8778
INFO:root:03:08:16 validation metrics:pearsonr:0.8786
INFO:root:03:08:16 Time cost=6.55s, throughput=229.45 samples/s
INFO:root:03:08:18 params saved in: ./output_dir/model_bert_STS-B_0.params
INFO:root:03:08:18 Time cost=51.48s
INFO:root:03:08:21 [Epoch 2 Batch 10/186] loss=0.2494, lr=0.0000174, metrics:pearsonr:0.8899
INFO:root:03:08:23 [Epoch 2 Batch 20/186] loss=0.2197, lr=0.0000171, metrics:pearsonr:0.8841
INFO:root:03:08:26 [Epoch 2 Batch 30/186] loss=0.2352, lr=0.0000169, metrics:pearsonr:0.8898
INFO:root:03:08:28 [Epoch 2 Batch 40/186] loss=0.2174, lr=0.0000166, metrics:pearsonr:0.8905
INFO:root:03:08:30 [Epoch 2 Batch 50/186] loss=0.1771, lr=0.0000164, metrics:pearsonr:0.8936
INFO:root:03:08:32 [Epoch 2 Batch 60/186] loss=0.1965, lr=0.0000161, metrics:pearsonr:0.8953
INFO:root:03:08:35 [Epoch 2 Batch 70/186] loss=0.2237, lr=0.0000159, metrics:pearsonr:0.8958
INFO:root:03:08:37 [Epoch 2 Batch 80/186] loss=0.2420, lr=0.0000156, metrics:pearsonr:0.8948
INFO:root:03:08:40 [Epoch 2 Batch 90/186] loss=0.2185, lr=0.0000154, metrics:pearsonr:0.8938
INFO:root:03:08:43 [Epoch 2 Batch 100/186] loss=0.1920, lr=0.0000152, metrics:pearsonr:0.8949
INFO:root:03:08:45 [Epoch 2 Batch 110/186] loss=0.1987, lr=0.0000149, metrics:pearsonr:0.8966
INFO:root:03:08:47 [Epoch 2 Batch 120/186] loss=0.1935, lr=0.0000147, metrics:pearsonr:0.8970
INFO:root:03:08:50 [Epoch 2 Batch 130/186] loss=0.2030, lr=0.0000144, metrics:pearsonr:0.8963
INFO:root:03:08:52 [Epoch 2 Batch 140/186] loss=0.2029, lr=0.0000142, metrics:pearsonr:0.8954
INFO:root:03:08:55 [Epoch 2 Batch 150/186] loss=0.1781, lr=0.0000139, metrics:pearsonr:0.8962
INFO:root:03:08:57 [Epoch 2 Batch 160/186] loss=0.1845, lr=0.0000137, metrics:pearsonr:0.8970
INFO:root:03:08:59 [Epoch 2 Batch 170/186] loss=0.2084, lr=0.0000134, metrics:pearsonr:0.8968
INFO:root:03:09:01 [Epoch 2 Batch 180/186] loss=0.1825, lr=0.0000132, metrics:pearsonr:0.8981
INFO:root:03:09:03 Now we are doing evaluation on dev with gpu(0).
INFO:root:03:09:03 [Batch 10/188] loss=0.1541, metrics:pearsonr:0.9411
INFO:root:03:09:03 [Batch 20/188] loss=0.2282, metrics:pearsonr:0.9346
INFO:root:03:09:03 [Batch 30/188] loss=0.1764, metrics:pearsonr:0.9325
INFO:root:03:09:04 [Batch 40/188] loss=0.1757, metrics:pearsonr:0.9322
INFO:root:03:09:04 [Batch 50/188] loss=0.2322, metrics:pearsonr:0.9278
INFO:root:03:09:04 [Batch 60/188] loss=0.1445, metrics:pearsonr:0.9303
INFO:root:03:09:05 [Batch 70/188] loss=0.3261, metrics:pearsonr:0.9222
INFO:root:03:09:05 [Batch 80/188] loss=0.3199, metrics:pearsonr:0.9165
INFO:root:03:09:05 [Batch 90/188] loss=0.3791, metrics:pearsonr:0.9055
INFO:root:03:09:06 [Batch 100/188] loss=0.2260, metrics:pearsonr:0.9024
INFO:root:03:09:06 [Batch 110/188] loss=0.2862, metrics:pearsonr:0.8955
INFO:root:03:09:06 [Batch 120/188] loss=0.3094, metrics:pearsonr:0.8911
INFO:root:03:09:07 [Batch 130/188] loss=0.2210, metrics:pearsonr:0.8910
INFO:root:03:09:07 [Batch 140/188] loss=0.1901, metrics:pearsonr:0.8935
INFO:root:03:09:08 [Batch 150/188] loss=0.1586, metrics:pearsonr:0.8950
INFO:root:03:09:08 [Batch 160/188] loss=0.2487, metrics:pearsonr:0.8944
INFO:root:03:09:08 [Batch 170/188] loss=0.2931, metrics:pearsonr:0.8925
INFO:root:03:09:09 [Batch 180/188] loss=0.2553, metrics:pearsonr:0.8919
INFO:root:03:09:09 validation metrics:pearsonr:0.8923
INFO:root:03:09:09 Time cost=6.38s, throughput=235.73 samples/s
INFO:root:03:09:11 params saved in: ./output_dir/model_bert_STS-B_1.params
INFO:root:03:09:11 Time cost=52.27s
INFO:root:03:09:13 [Epoch 3 Batch 10/186] loss=0.1206, lr=0.0000128, metrics:pearsonr:0.9304
INFO:root:03:09:16 [Epoch 3 Batch 20/186] loss=0.1202, lr=0.0000125, metrics:pearsonr:0.9369
INFO:root:03:09:18 [Epoch 3 Batch 30/186] loss=0.1122, lr=0.0000123, metrics:pearsonr:0.9404
INFO:root:03:09:20 [Epoch 3 Batch 40/186] loss=0.1261, lr=0.0000120, metrics:pearsonr:0.9401
INFO:root:03:09:23 [Epoch 3 Batch 50/186] loss=0.1225, lr=0.0000118, metrics:pearsonr:0.9406
INFO:root:03:09:25 [Epoch 3 Batch 60/186] loss=0.1077, lr=0.0000115, metrics:pearsonr:0.9435
INFO:root:03:09:27 [Epoch 3 Batch 70/186] loss=0.1268, lr=0.0000113, metrics:pearsonr:0.9439
INFO:root:03:09:29 [Epoch 3 Batch 80/186] loss=0.1334, lr=0.0000111, metrics:pearsonr:0.9434
INFO:root:03:09:31 [Epoch 3 Batch 90/186] loss=0.1153, lr=0.0000108, metrics:pearsonr:0.9430
INFO:root:03:09:33 [Epoch 3 Batch 100/186] loss=0.0872, lr=0.0000106, metrics:pearsonr:0.9443
INFO:root:03:09:36 [Epoch 3 Batch 110/186] loss=0.1072, lr=0.0000103, metrics:pearsonr:0.9440
INFO:root:03:09:39 [Epoch 3 Batch 120/186] loss=0.1217, lr=0.0000101, metrics:pearsonr:0.9435
INFO:root:03:09:41 [Epoch 3 Batch 130/186] loss=0.1133, lr=0.0000098, metrics:pearsonr:0.9433
INFO:root:03:09:43 [Epoch 3 Batch 140/186] loss=0.1295, lr=0.0000096, metrics:pearsonr:0.9424
INFO:root:03:09:45 [Epoch 3 Batch 150/186] loss=0.1231, lr=0.0000093, metrics:pearsonr:0.9421
INFO:root:03:09:47 [Epoch 3 Batch 160/186] loss=0.1239, lr=0.0000091, metrics:pearsonr:0.9421
INFO:root:03:09:50 [Epoch 3 Batch 170/186] loss=0.1119, lr=0.0000088, metrics:pearsonr:0.9425
INFO:root:03:09:52 [Epoch 3 Batch 180/186] loss=0.1194, lr=0.0000086, metrics:pearsonr:0.9426
INFO:root:03:09:53 Now we are doing evaluation on dev with gpu(0).
INFO:root:03:09:54 [Batch 10/188] loss=0.1478, metrics:pearsonr:0.9437
INFO:root:03:09:54 [Batch 20/188] loss=0.2019, metrics:pearsonr:0.9400
INFO:root:03:09:54 [Batch 30/188] loss=0.1659, metrics:pearsonr:0.9371
INFO:root:03:09:55 [Batch 40/188] loss=0.1704, metrics:pearsonr:0.9358
INFO:root:03:09:55 [Batch 50/188] loss=0.2135, metrics:pearsonr:0.9309
INFO:root:03:09:55 [Batch 60/188] loss=0.1156, metrics:pearsonr:0.9343
INFO:root:03:09:56 [Batch 70/188] loss=0.3245, metrics:pearsonr:0.9248
INFO:root:03:09:56 [Batch 80/188] loss=0.2902, metrics:pearsonr:0.9195
INFO:root:03:09:56 [Batch 90/188] loss=0.4137, metrics:pearsonr:0.9066
INFO:root:03:09:57 [Batch 100/188] loss=0.2374, metrics:pearsonr:0.9034
INFO:root:03:09:57 [Batch 110/188] loss=0.2806, metrics:pearsonr:0.8964
INFO:root:03:09:57 [Batch 120/188] loss=0.3361, metrics:pearsonr:0.8912
INFO:root:03:09:58 [Batch 130/188] loss=0.2348, metrics:pearsonr:0.8903
INFO:root:03:09:58 [Batch 140/188] loss=0.1497, metrics:pearsonr:0.8931
INFO:root:03:09:59 [Batch 150/188] loss=0.1338, metrics:pearsonr:0.8946
INFO:root:03:09:59 [Batch 160/188] loss=0.2049, metrics:pearsonr:0.8943
INFO:root:03:09:59 [Batch 170/188] loss=0.2400, metrics:pearsonr:0.8928
INFO:root:03:10:00 [Batch 180/188] loss=0.2388, metrics:pearsonr:0.8921
INFO:root:03:10:00 validation metrics:pearsonr:0.8930
INFO:root:03:10:00 Time cost=6.43s, throughput=233.89 samples/s
INFO:root:03:10:01 params saved in: ./output_dir/model_bert_STS-B_2.params
INFO:root:03:10:01 Time cost=50.93s
INFO:root:03:10:04 [Epoch 4 Batch 10/186] loss=0.0826, lr=0.0000082, metrics:pearsonr:0.9631
INFO:root:03:10:07 [Epoch 4 Batch 20/186] loss=0.0842, lr=0.0000079, metrics:pearsonr:0.9626
INFO:root:03:10:09 [Epoch 4 Batch 30/186] loss=0.0744, lr=0.0000077, metrics:pearsonr:0.9628
INFO:root:03:10:11 [Epoch 4 Batch 40/186] loss=0.0843, lr=0.0000074, metrics:pearsonr:0.9619
INFO:root:03:10:14 [Epoch 4 Batch 50/186] loss=0.0675, lr=0.0000072, metrics:pearsonr:0.9625
INFO:root:03:10:16 [Epoch 4 Batch 60/186] loss=0.0714, lr=0.0000069, metrics:pearsonr:0.9625
INFO:root:03:10:18 [Epoch 4 Batch 70/186] loss=0.0830, lr=0.0000067, metrics:pearsonr:0.9625
INFO:root:03:10:21 [Epoch 4 Batch 80/186] loss=0.0955, lr=0.0000065, metrics:pearsonr:0.9608
INFO:root:03:10:23 [Epoch 4 Batch 90/186] loss=0.0699, lr=0.0000062, metrics:pearsonr:0.9607
INFO:root:03:10:25 [Epoch 4 Batch 100/186] loss=0.0753, lr=0.0000060, metrics:pearsonr:0.9613
INFO:root:03:10:27 [Epoch 4 Batch 110/186] loss=0.0866, lr=0.0000057, metrics:pearsonr:0.9614
INFO:root:03:10:29 [Epoch 4 Batch 120/186] loss=0.0715, lr=0.0000055, metrics:pearsonr:0.9615
INFO:root:03:10:32 [Epoch 4 Batch 130/186] loss=0.0845, lr=0.0000052, metrics:pearsonr:0.9614
INFO:root:03:10:34 [Epoch 4 Batch 140/186] loss=0.0870, lr=0.0000050, metrics:pearsonr:0.9615
INFO:root:03:10:36 [Epoch 4 Batch 150/186] loss=0.0783, lr=0.0000047, metrics:pearsonr:0.9617
INFO:root:03:10:38 [Epoch 4 Batch 160/186] loss=0.0744, lr=0.0000045, metrics:pearsonr:0.9616
INFO:root:03:10:41 [Epoch 4 Batch 170/186] loss=0.0714, lr=0.0000042, metrics:pearsonr:0.9618
INFO:root:03:10:43 [Epoch 4 Batch 180/186] loss=0.0722, lr=0.0000040, metrics:pearsonr:0.9620
INFO:root:03:10:44 Now we are doing evaluation on dev with gpu(0).
INFO:root:03:10:44 [Batch 10/188] loss=0.1472, metrics:pearsonr:0.9441
INFO:root:03:10:45 [Batch 20/188] loss=0.1843, metrics:pearsonr:0.9435
INFO:root:03:10:45 [Batch 30/188] loss=0.1663, metrics:pearsonr:0.9398
INFO:root:03:10:45 [Batch 40/188] loss=0.1747, metrics:pearsonr:0.9377
INFO:root:03:10:46 [Batch 50/188] loss=0.2121, metrics:pearsonr:0.9335
INFO:root:03:10:46 [Batch 60/188] loss=0.1284, metrics:pearsonr:0.9361
INFO:root:03:10:46 [Batch 70/188] loss=0.3554, metrics:pearsonr:0.9253
INFO:root:03:10:47 [Batch 80/188] loss=0.3069, metrics:pearsonr:0.9197
INFO:root:03:10:47 [Batch 90/188] loss=0.4175, metrics:pearsonr:0.9067
INFO:root:03:10:47 [Batch 100/188] loss=0.2401, metrics:pearsonr:0.9032
INFO:root:03:10:48 [Batch 110/188] loss=0.2878, metrics:pearsonr:0.8959
INFO:root:03:10:48 [Batch 120/188] loss=0.3405, metrics:pearsonr:0.8902
INFO:root:03:10:48 [Batch 130/188] loss=0.2275, metrics:pearsonr:0.8897
INFO:root:03:10:49 [Batch 140/188] loss=0.1469, metrics:pearsonr:0.8930
INFO:root:03:10:49 [Batch 150/188] loss=0.1408, metrics:pearsonr:0.8945
INFO:root:03:10:50 [Batch 160/188] loss=0.2143, metrics:pearsonr:0.8942
INFO:root:03:10:50 [Batch 170/188] loss=0.2704, metrics:pearsonr:0.8923
INFO:root:03:10:50 [Batch 180/188] loss=0.2419, metrics:pearsonr:0.8918
INFO:root:03:10:51 validation metrics:pearsonr:0.8926
INFO:root:03:10:51 Time cost=6.34s, throughput=237.32 samples/s
INFO:root:03:10:52 params saved in: ./output_dir/model_bert_STS-B_3.params
INFO:root:03:10:52 Time cost=50.67s
INFO:root:03:10:54 [Epoch 5 Batch 10/186] loss=0.0624, lr=0.0000036, metrics:pearsonr:0.9722
INFO:root:03:10:57 [Epoch 5 Batch 20/186] loss=0.0607, lr=0.0000033, metrics:pearsonr:0.9707
INFO:root:03:11:00 [Epoch 5 Batch 30/186] loss=0.0554, lr=0.0000031, metrics:pearsonr:0.9701
INFO:root:03:11:02 [Epoch 5 Batch 40/186] loss=0.0603, lr=0.0000028, metrics:pearsonr:0.9706
INFO:root:03:11:04 [Epoch 5 Batch 50/186] loss=0.0558, lr=0.0000026, metrics:pearsonr:0.9704
INFO:root:03:11:06 [Epoch 5 Batch 60/186] loss=0.0680, lr=0.0000023, metrics:pearsonr:0.9702
INFO:root:03:11:09 [Epoch 5 Batch 70/186] loss=0.0502, lr=0.0000021, metrics:pearsonr:0.9707
INFO:root:03:11:11 [Epoch 5 Batch 80/186] loss=0.0678, lr=0.0000019, metrics:pearsonr:0.9708
INFO:root:03:11:14 [Epoch 5 Batch 90/186] loss=0.0540, lr=0.0000016, metrics:pearsonr:0.9710
INFO:root:03:11:16 [Epoch 5 Batch 100/186] loss=0.0603, lr=0.0000014, metrics:pearsonr:0.9712
INFO:root:03:11:18 [Epoch 5 Batch 110/186] loss=0.0532, lr=0.0000011, metrics:pearsonr:0.9718
INFO:root:03:11:20 [Epoch 5 Batch 120/186] loss=0.0544, lr=0.0000009, metrics:pearsonr:0.9721
INFO:root:03:11:22 [Epoch 5 Batch 130/186] loss=0.0690, lr=0.0000006, metrics:pearsonr:0.9719
INFO:root:03:11:25 [Epoch 5 Batch 140/186] loss=0.0593, lr=0.0000004, metrics:pearsonr:0.9719
INFO:root:03:11:27 [Epoch 5 Batch 150/186] loss=0.0622, lr=0.0000001, metrics:pearsonr:0.9716
INFO:root:03:11:28 Finish training step: 898
INFO:root:03:11:28 Now we are doing evaluation on dev with gpu(0).
INFO:root:03:11:28 [Batch 10/188] loss=0.1495, metrics:pearsonr:0.9434
INFO:root:03:11:29 [Batch 20/188] loss=0.1857, metrics:pearsonr:0.9431
INFO:root:03:11:29 [Batch 30/188] loss=0.1682, metrics:pearsonr:0.9392
INFO:root:03:11:29 [Batch 40/188] loss=0.1697, metrics:pearsonr:0.9376
INFO:root:03:11:29 [Batch 50/188] loss=0.2129, metrics:pearsonr:0.9332
INFO:root:03:11:30 [Batch 60/188] loss=0.1173, metrics:pearsonr:0.9364
INFO:root:03:11:30 [Batch 70/188] loss=0.3367, metrics:pearsonr:0.9264
INFO:root:03:11:30 [Batch 80/188] loss=0.2849, metrics:pearsonr:0.9213
INFO:root:03:11:31 [Batch 90/188] loss=0.4022, metrics:pearsonr:0.9087
INFO:root:03:11:31 [Batch 100/188] loss=0.2354, metrics:pearsonr:0.9050
INFO:root:03:11:31 [Batch 110/188] loss=0.2996, metrics:pearsonr:0.8974
INFO:root:03:11:32 [Batch 120/188] loss=0.3324, metrics:pearsonr:0.8919
INFO:root:03:11:32 [Batch 130/188] loss=0.2239, metrics:pearsonr:0.8914
INFO:root:03:11:33 [Batch 140/188] loss=0.1464, metrics:pearsonr:0.8945
INFO:root:03:11:33 [Batch 150/188] loss=0.1360, metrics:pearsonr:0.8961
INFO:root:03:11:34 [Batch 160/188] loss=0.2179, metrics:pearsonr:0.8956
INFO:root:03:11:34 [Batch 170/188] loss=0.2685, metrics:pearsonr:0.8937
INFO:root:03:11:34 [Batch 180/188] loss=0.2394, metrics:pearsonr:0.8932
INFO:root:03:11:34 validation metrics:pearsonr:0.8939
INFO:root:03:11:34 Time cost=6.45s, throughput=233.08 samples/s
INFO:root:03:11:36 params saved in: ./output_dir/model_bert_STS-B_4.params
INFO:root:03:11:36 Time cost=43.87s
INFO:root:03:11:37 Best model at epoch 4. Validation metrics:pearsonr:0.8939
INFO:root:03:11:37 Now we are doing testing on test with gpu(0).
INFO:root:03:11:42 Time cost=5.61s, throughput=246.81 samples/s

bert_large
INFO:root:05:55:12 Namespace(accumulate=None, batch_size=16, bert_dataset='book_corpus_wiki_en_uncased', bert_model='bert_24_1024_16', calib_mode='customize', deploy=False, dev_batch_size=8, dtype='float32', early_stop=None, epochs=5, epsilon=1e-06, gpu=0, log_interval=10, lr=2e-05, max_len=128, model_parameters=None, model_prefix=None, num_calib_batches=5, only_calibration=False, only_inference=False, optimizer='bertadam', output_dir='./output_dir', pretrained_bert_parameters=None, quantized_dtype='auto', round_to=None, seed=24, task_name='STS-B', training_steps=None, warmup_ratio=0.1)
INFO:root:05:55:18 processing dataset...
INFO:root:05:55:20 Now we are doing BERT classification training on gpu(0)!
INFO:root:05:55:20 training steps=1796
INFO:root:05:55:23 [Epoch 1 Batch 10/365] loss=5.9088, lr=0.0000010, metrics:pearsonr:-0.1328
INFO:root:05:55:26 [Epoch 1 Batch 20/365] loss=5.6034, lr=0.0000021, metrics:pearsonr:0.0166
INFO:root:05:55:28 [Epoch 1 Batch 30/365] loss=3.6710, lr=0.0000032, metrics:pearsonr:0.0520
INFO:root:05:55:30 [Epoch 1 Batch 40/365] loss=1.2748, lr=0.0000044, metrics:pearsonr:0.0805
INFO:root:05:55:33 [Epoch 1 Batch 50/365] loss=1.2055, lr=0.0000055, metrics:pearsonr:0.0441
INFO:root:05:55:35 [Epoch 1 Batch 60/365] loss=0.7445, lr=0.0000066, metrics:pearsonr:0.0990
INFO:root:05:55:38 [Epoch 1 Batch 70/365] loss=0.5203, lr=0.0000077, metrics:pearsonr:0.1367
INFO:root:05:55:41 [Epoch 1 Batch 80/365] loss=0.4285, lr=0.0000088, metrics:pearsonr:0.1882
INFO:root:05:55:43 [Epoch 1 Batch 90/365] loss=0.5834, lr=0.0000099, metrics:pearsonr:0.2135
INFO:root:05:55:45 [Epoch 1 Batch 100/365] loss=0.9410, lr=0.0000111, metrics:pearsonr:0.2174
INFO:root:05:55:47 [Epoch 1 Batch 110/365] loss=1.3413, lr=0.0000122, metrics:pearsonr:0.2213
INFO:root:05:55:50 [Epoch 1 Batch 120/365] loss=0.5442, lr=0.0000133, metrics:pearsonr:0.2479
INFO:root:05:55:52 [Epoch 1 Batch 130/365] loss=0.4598, lr=0.0000144, metrics:pearsonr:0.2719
INFO:root:05:55:54 [Epoch 1 Batch 140/365] loss=0.4402, lr=0.0000155, metrics:pearsonr:0.2943
INFO:root:05:55:56 [Epoch 1 Batch 150/365] loss=0.4766, lr=0.0000166, metrics:pearsonr:0.3187
INFO:root:05:55:58 [Epoch 1 Batch 160/365] loss=0.4791, lr=0.0000178, metrics:pearsonr:0.3436
INFO:root:05:56:01 [Epoch 1 Batch 170/365] loss=0.5383, lr=0.0000189, metrics:pearsonr:0.3613
INFO:root:05:56:03 [Epoch 1 Batch 180/365] loss=0.6803, lr=0.0000200, metrics:pearsonr:0.3771
INFO:root:05:56:06 [Epoch 1 Batch 190/365] loss=0.6158, lr=0.0000199, metrics:pearsonr:0.3916
INFO:root:05:56:08 [Epoch 1 Batch 200/365] loss=0.4681, lr=0.0000198, metrics:pearsonr:0.4066
INFO:root:05:56:10 [Epoch 1 Batch 210/365] loss=0.4650, lr=0.0000196, metrics:pearsonr:0.4188
INFO:root:05:56:13 [Epoch 1 Batch 220/365] loss=0.5477, lr=0.0000195, metrics:pearsonr:0.4298
INFO:root:05:56:15 [Epoch 1 Batch 230/365] loss=0.4883, lr=0.0000194, metrics:pearsonr:0.4397
INFO:root:05:56:17 [Epoch 1 Batch 240/365] loss=0.4293, lr=0.0000193, metrics:pearsonr:0.4516
INFO:root:05:56:20 [Epoch 1 Batch 250/365] loss=0.3516, lr=0.0000191, metrics:pearsonr:0.4631
INFO:root:05:56:22 [Epoch 1 Batch 260/365] loss=0.3900, lr=0.0000190, metrics:pearsonr:0.4755
INFO:root:05:56:24 [Epoch 1 Batch 270/365] loss=0.4199, lr=0.0000189, metrics:pearsonr:0.4831
INFO:root:05:56:27 [Epoch 1 Batch 280/365] loss=0.4984, lr=0.0000188, metrics:pearsonr:0.4956
INFO:root:05:56:29 [Epoch 1 Batch 290/365] loss=0.2817, lr=0.0000186, metrics:pearsonr:0.5045
INFO:root:05:56:32 [Epoch 1 Batch 300/365] loss=0.4050, lr=0.0000185, metrics:pearsonr:0.5095
INFO:root:05:56:34 [Epoch 1 Batch 310/365] loss=0.3270, lr=0.0000184, metrics:pearsonr:0.5189
INFO:root:05:56:36 [Epoch 1 Batch 320/365] loss=0.3190, lr=0.0000183, metrics:pearsonr:0.5297
INFO:root:05:56:39 [Epoch 1 Batch 330/365] loss=0.3576, lr=0.0000181, metrics:pearsonr:0.5383
INFO:root:05:56:41 [Epoch 1 Batch 340/365] loss=0.3031, lr=0.0000180, metrics:pearsonr:0.5473
INFO:root:05:56:44 [Epoch 1 Batch 350/365] loss=0.2992, lr=0.0000179, metrics:pearsonr:0.5529
INFO:root:05:56:46 [Epoch 1 Batch 360/365] loss=0.4045, lr=0.0000178, metrics:pearsonr:0.5603
INFO:root:05:56:47 Now we are doing evaluation on dev with gpu(0).
INFO:root:05:56:47 [Batch 10/188] loss=0.2065, metrics:pearsonr:0.9261
INFO:root:05:56:48 [Batch 20/188] loss=0.2143, metrics:pearsonr:0.9363
INFO:root:05:56:48 [Batch 30/188] loss=0.2048, metrics:pearsonr:0.9345
INFO:root:05:56:49 [Batch 40/188] loss=0.3246, metrics:pearsonr:0.9210
INFO:root:05:56:49 [Batch 50/188] loss=0.2263, metrics:pearsonr:0.9176
INFO:root:05:56:49 [Batch 60/188] loss=0.2813, metrics:pearsonr:0.9135
INFO:root:05:56:50 [Batch 70/188] loss=0.2643, metrics:pearsonr:0.9118
INFO:root:05:56:50 [Batch 80/188] loss=0.3157, metrics:pearsonr:0.9074
INFO:root:05:56:51 [Batch 90/188] loss=0.4741, metrics:pearsonr:0.8916
INFO:root:05:56:52 [Batch 100/188] loss=0.3953, metrics:pearsonr:0.8826
INFO:root:05:56:52 [Batch 110/188] loss=0.3391, metrics:pearsonr:0.8734
INFO:root:05:56:53 [Batch 120/188] loss=0.5389, metrics:pearsonr:0.8622
INFO:root:05:56:53 [Batch 130/188] loss=0.3413, metrics:pearsonr:0.8593
INFO:root:05:56:54 [Batch 140/188] loss=0.2015, metrics:pearsonr:0.8624
INFO:root:05:56:55 [Batch 150/188] loss=0.1945, metrics:pearsonr:0.8641
INFO:root:05:56:55 [Batch 160/188] loss=0.2443, metrics:pearsonr:0.8642
INFO:root:05:56:56 [Batch 170/188] loss=0.3667, metrics:pearsonr:0.8595
INFO:root:05:56:56 [Batch 180/188] loss=0.2708, metrics:pearsonr:0.8597
INFO:root:05:56:57 validation metrics:pearsonr:0.8618
INFO:root:05:56:57 Time cost=9.84s, throughput=152.83 samples/s
INFO:root:05:57:11 params saved in: ./output_dir/model_bert_STS-B_0.params
INFO:root:05:57:11 Time cost=111.35s
INFO:root:05:57:14 [Epoch 2 Batch 10/365] loss=0.2487, lr=0.0000176, metrics:pearsonr:0.8770
INFO:root:05:57:16 [Epoch 2 Batch 20/365] loss=0.2605, lr=0.0000175, metrics:pearsonr:0.8720
INFO:root:05:57:18 [Epoch 2 Batch 30/365] loss=0.2676, lr=0.0000173, metrics:pearsonr:0.8727
INFO:root:05:57:21 [Epoch 2 Batch 40/365] loss=0.2535, lr=0.0000172, metrics:pearsonr:0.8729
INFO:root:05:57:23 [Epoch 2 Batch 50/365] loss=0.2375, lr=0.0000171, metrics:pearsonr:0.8737
INFO:root:05:57:26 [Epoch 2 Batch 60/365] loss=0.2064, lr=0.0000170, metrics:pearsonr:0.8741
INFO:root:05:57:29 [Epoch 2 Batch 70/365] loss=0.3175, lr=0.0000168, metrics:pearsonr:0.8690
INFO:root:05:57:31 [Epoch 2 Batch 80/365] loss=0.2137, lr=0.0000167, metrics:pearsonr:0.8726
INFO:root:05:57:33 [Epoch 2 Batch 90/365] loss=0.2705, lr=0.0000166, metrics:pearsonr:0.8738
INFO:root:05:57:36 [Epoch 2 Batch 100/365] loss=0.1984, lr=0.0000165, metrics:pearsonr:0.8775
INFO:root:05:57:38 [Epoch 2 Batch 110/365] loss=0.2380, lr=0.0000164, metrics:pearsonr:0.8770
INFO:root:05:57:41 [Epoch 2 Batch 120/365] loss=0.2395, lr=0.0000162, metrics:pearsonr:0.8767
INFO:root:05:57:43 [Epoch 2 Batch 130/365] loss=0.1869, lr=0.0000161, metrics:pearsonr:0.8789
INFO:root:05:57:46 [Epoch 2 Batch 140/365] loss=0.2181, lr=0.0000160, metrics:pearsonr:0.8801
INFO:root:05:57:48 [Epoch 2 Batch 150/365] loss=0.2233, lr=0.0000159, metrics:pearsonr:0.8807
INFO:root:05:57:51 [Epoch 2 Batch 160/365] loss=0.2479, lr=0.0000157, metrics:pearsonr:0.8802
INFO:root:05:57:53 [Epoch 2 Batch 170/365] loss=0.2074, lr=0.0000156, metrics:pearsonr:0.8811
INFO:root:05:57:55 [Epoch 2 Batch 180/365] loss=0.2525, lr=0.0000155, metrics:pearsonr:0.8803
INFO:root:05:57:58 [Epoch 2 Batch 190/365] loss=0.2129, lr=0.0000154, metrics:pearsonr:0.8798
INFO:root:05:58:00 [Epoch 2 Batch 200/365] loss=0.2514, lr=0.0000152, metrics:pearsonr:0.8798
INFO:root:05:58:03 [Epoch 2 Batch 210/365] loss=0.2304, lr=0.0000151, metrics:pearsonr:0.8805
INFO:root:05:58:05 [Epoch 2 Batch 220/365] loss=0.3245, lr=0.0000150, metrics:pearsonr:0.8782
INFO:root:05:58:07 [Epoch 2 Batch 230/365] loss=0.2353, lr=0.0000149, metrics:pearsonr:0.8789
INFO:root:05:58:09 [Epoch 2 Batch 240/365] loss=0.1856, lr=0.0000147, metrics:pearsonr:0.8806
INFO:root:05:58:12 [Epoch 2 Batch 250/365] loss=0.1925, lr=0.0000146, metrics:pearsonr:0.8820
INFO:root:05:58:14 [Epoch 2 Batch 260/365] loss=0.1730, lr=0.0000145, metrics:pearsonr:0.8841
INFO:root:05:58:17 [Epoch 2 Batch 270/365] loss=0.2638, lr=0.0000144, metrics:pearsonr:0.8843
INFO:root:05:58:19 [Epoch 2 Batch 280/365] loss=0.2015, lr=0.0000142, metrics:pearsonr:0.8850
INFO:root:05:58:21 [Epoch 2 Batch 290/365] loss=0.2189, lr=0.0000141, metrics:pearsonr:0.8854
INFO:root:05:58:23 [Epoch 2 Batch 300/365] loss=0.2169, lr=0.0000140, metrics:pearsonr:0.8858
INFO:root:05:58:26 [Epoch 2 Batch 310/365] loss=0.2260, lr=0.0000139, metrics:pearsonr:0.8859
INFO:root:05:58:28 [Epoch 2 Batch 320/365] loss=0.2258, lr=0.0000138, metrics:pearsonr:0.8860
INFO:root:05:58:31 [Epoch 2 Batch 330/365] loss=0.1923, lr=0.0000136, metrics:pearsonr:0.8868
INFO:root:05:58:33 [Epoch 2 Batch 340/365] loss=0.1962, lr=0.0000135, metrics:pearsonr:0.8863
INFO:root:05:58:36 [Epoch 2 Batch 350/365] loss=0.1135, lr=0.0000134, metrics:pearsonr:0.8882
INFO:root:05:58:38 [Epoch 2 Batch 360/365] loss=0.2198, lr=0.0000133, metrics:pearsonr:0.8883
INFO:root:05:58:39 Now we are doing evaluation on dev with gpu(0).
INFO:root:05:58:40 [Batch 10/188] loss=0.1657, metrics:pearsonr:0.9591
INFO:root:05:58:40 [Batch 20/188] loss=0.2282, metrics:pearsonr:0.9544
INFO:root:05:58:41 [Batch 30/188] loss=0.1527, metrics:pearsonr:0.9523
INFO:root:05:58:41 [Batch 40/188] loss=0.2519, metrics:pearsonr:0.9424
INFO:root:05:58:41 [Batch 50/188] loss=0.1994, metrics:pearsonr:0.9389
INFO:root:05:58:42 [Batch 60/188] loss=0.2618, metrics:pearsonr:0.9352
INFO:root:05:58:42 [Batch 70/188] loss=0.3323, metrics:pearsonr:0.9268
INFO:root:05:58:43 [Batch 80/188] loss=0.3198, metrics:pearsonr:0.9210
INFO:root:05:58:43 [Batch 90/188] loss=0.4153, metrics:pearsonr:0.9076
INFO:root:05:58:44 [Batch 100/188] loss=0.3439, metrics:pearsonr:0.8993
INFO:root:05:58:45 [Batch 110/188] loss=0.4107, metrics:pearsonr:0.8913
INFO:root:05:58:45 [Batch 120/188] loss=0.4447, metrics:pearsonr:0.8824
INFO:root:05:58:46 [Batch 130/188] loss=0.2742, metrics:pearsonr:0.8819
INFO:root:05:58:47 [Batch 140/188] loss=0.1567, metrics:pearsonr:0.8852
INFO:root:05:58:47 [Batch 150/188] loss=0.1401, metrics:pearsonr:0.8875
INFO:root:05:58:48 [Batch 160/188] loss=0.2142, metrics:pearsonr:0.8877
INFO:root:05:58:48 [Batch 170/188] loss=0.2767, metrics:pearsonr:0.8862
INFO:root:05:58:49 [Batch 180/188] loss=0.2853, metrics:pearsonr:0.8866
INFO:root:05:58:49 validation metrics:pearsonr:0.8875
INFO:root:05:58:49 Time cost=9.83s, throughput=152.93 samples/s
INFO:root:05:59:09 params saved in: ./output_dir/model_bert_STS-B_1.params
INFO:root:05:59:09 Time cost=117.51s
INFO:root:05:59:12 [Epoch 3 Batch 10/365] loss=0.1139, lr=0.0000131, metrics:pearsonr:0.9455
INFO:root:05:59:14 [Epoch 3 Batch 20/365] loss=0.1124, lr=0.0000129, metrics:pearsonr:0.9440
INFO:root:05:59:17 [Epoch 3 Batch 30/365] loss=0.1143, lr=0.0000128, metrics:pearsonr:0.9455
INFO:root:05:59:19 [Epoch 3 Batch 40/365] loss=0.1301, lr=0.0000127, metrics:pearsonr:0.9434
INFO:root:05:59:22 [Epoch 3 Batch 50/365] loss=0.1481, lr=0.0000126, metrics:pearsonr:0.9404
INFO:root:05:59:24 [Epoch 3 Batch 60/365] loss=0.1067, lr=0.0000125, metrics:pearsonr:0.9395
INFO:root:05:59:26 [Epoch 3 Batch 70/365] loss=0.1241, lr=0.0000123, metrics:pearsonr:0.9404
INFO:root:05:59:29 [Epoch 3 Batch 80/365] loss=0.1442, lr=0.0000122, metrics:pearsonr:0.9389
INFO:root:05:59:32 [Epoch 3 Batch 90/365] loss=0.1290, lr=0.0000121, metrics:pearsonr:0.9384
INFO:root:05:59:34 [Epoch 3 Batch 100/365] loss=0.1184, lr=0.0000120, metrics:pearsonr:0.9384
INFO:root:05:59:37 [Epoch 3 Batch 110/365] loss=0.1157, lr=0.0000118, metrics:pearsonr:0.9395
INFO:root:05:59:39 [Epoch 3 Batch 120/365] loss=0.1146, lr=0.0000117, metrics:pearsonr:0.9404
INFO:root:05:59:42 [Epoch 3 Batch 130/365] loss=0.1178, lr=0.0000116, metrics:pearsonr:0.9405
INFO:root:05:59:45 [Epoch 3 Batch 140/365] loss=0.1157, lr=0.0000115, metrics:pearsonr:0.9401
INFO:root:05:59:47 [Epoch 3 Batch 150/365] loss=0.1136, lr=0.0000113, metrics:pearsonr:0.9407
INFO:root:05:59:49 [Epoch 3 Batch 160/365] loss=0.0969, lr=0.0000112, metrics:pearsonr:0.9417
INFO:root:05:59:52 [Epoch 3 Batch 170/365] loss=0.1443, lr=0.0000111, metrics:pearsonr:0.9415
INFO:root:05:59:54 [Epoch 3 Batch 180/365] loss=0.1200, lr=0.0000110, metrics:pearsonr:0.9414
INFO:root:05:59:56 [Epoch 3 Batch 190/365] loss=0.1120, lr=0.0000108, metrics:pearsonr:0.9417
INFO:root:05:59:58 [Epoch 3 Batch 200/365] loss=0.1010, lr=0.0000107, metrics:pearsonr:0.9421
INFO:root:06:00:01 [Epoch 3 Batch 210/365] loss=0.1267, lr=0.0000106, metrics:pearsonr:0.9419
INFO:root:06:00:03 [Epoch 3 Batch 220/365] loss=0.1015, lr=0.0000105, metrics:pearsonr:0.9429
INFO:root:06:00:05 [Epoch 3 Batch 230/365] loss=0.0999, lr=0.0000104, metrics:pearsonr:0.9437
INFO:root:06:00:08 [Epoch 3 Batch 240/365] loss=0.1128, lr=0.0000102, metrics:pearsonr:0.9439
INFO:root:06:00:10 [Epoch 3 Batch 250/365] loss=0.1096, lr=0.0000101, metrics:pearsonr:0.9446
INFO:root:06:00:12 [Epoch 3 Batch 260/365] loss=0.1281, lr=0.0000100, metrics:pearsonr:0.9442
INFO:root:06:00:14 [Epoch 3 Batch 270/365] loss=0.0959, lr=0.0000099, metrics:pearsonr:0.9445
INFO:root:06:00:17 [Epoch 3 Batch 280/365] loss=0.1201, lr=0.0000097, metrics:pearsonr:0.9442
INFO:root:06:00:19 [Epoch 3 Batch 290/365] loss=0.0801, lr=0.0000096, metrics:pearsonr:0.9448
INFO:root:06:00:22 [Epoch 3 Batch 300/365] loss=0.1135, lr=0.0000095, metrics:pearsonr:0.9450
INFO:root:06:00:24 [Epoch 3 Batch 310/365] loss=0.1475, lr=0.0000094, metrics:pearsonr:0.9445
INFO:root:06:00:26 [Epoch 3 Batch 320/365] loss=0.1083, lr=0.0000092, metrics:pearsonr:0.9446
INFO:root:06:00:28 [Epoch 3 Batch 330/365] loss=0.1071, lr=0.0000091, metrics:pearsonr:0.9445
INFO:root:06:00:30 [Epoch 3 Batch 340/365] loss=0.1316, lr=0.0000090, metrics:pearsonr:0.9442
INFO:root:06:00:33 [Epoch 3 Batch 350/365] loss=0.1042, lr=0.0000089, metrics:pearsonr:0.9443
INFO:root:06:00:35 [Epoch 3 Batch 360/365] loss=0.0985, lr=0.0000087, metrics:pearsonr:0.9443
INFO:root:06:00:37 Now we are doing evaluation on dev with gpu(0).
INFO:root:06:00:37 [Batch 10/188] loss=0.1306, metrics:pearsonr:0.9539
INFO:root:06:00:38 [Batch 20/188] loss=0.1624, metrics:pearsonr:0.9538
INFO:root:06:00:38 [Batch 30/188] loss=0.1207, metrics:pearsonr:0.9517
INFO:root:06:00:39 [Batch 40/188] loss=0.1636, metrics:pearsonr:0.9474
INFO:root:06:00:39 [Batch 50/188] loss=0.1667, metrics:pearsonr:0.9432
INFO:root:06:00:39 [Batch 60/188] loss=0.1701, metrics:pearsonr:0.9413
INFO:root:06:00:40 [Batch 70/188] loss=0.2209, metrics:pearsonr:0.9365
INFO:root:06:00:40 [Batch 80/188] loss=0.2460, metrics:pearsonr:0.9316
INFO:root:06:00:41 [Batch 90/188] loss=0.4080, metrics:pearsonr:0.9183
INFO:root:06:00:42 [Batch 100/188] loss=0.3366, metrics:pearsonr:0.9099
INFO:root:06:00:42 [Batch 110/188] loss=0.3965, metrics:pearsonr:0.9002
INFO:root:06:00:43 [Batch 120/188] loss=0.4522, metrics:pearsonr:0.8908
INFO:root:06:00:43 [Batch 130/188] loss=0.2592, metrics:pearsonr:0.8899
INFO:root:06:00:44 [Batch 140/188] loss=0.1407, metrics:pearsonr:0.8931
INFO:root:06:00:45 [Batch 150/188] loss=0.1213, metrics:pearsonr:0.8953
INFO:root:06:00:45 [Batch 160/188] loss=0.2082, metrics:pearsonr:0.8948
INFO:root:06:00:46 [Batch 170/188] loss=0.2635, metrics:pearsonr:0.8925
INFO:root:06:00:46 [Batch 180/188] loss=0.2488, metrics:pearsonr:0.8921
INFO:root:06:00:47 validation metrics:pearsonr:0.8930
INFO:root:06:00:47 Time cost=9.62s, throughput=156.37 samples/s
INFO:root:06:01:05 params saved in: ./output_dir/model_bert_STS-B_2.params
INFO:root:06:01:05 Time cost=116.61s
INFO:root:06:01:07 [Epoch 4 Batch 10/365] loss=0.0812, lr=0.0000086, metrics:pearsonr:0.9662
INFO:root:06:01:10 [Epoch 4 Batch 20/365] loss=0.1062, lr=0.0000084, metrics:pearsonr:0.9578
INFO:root:06:01:12 [Epoch 4 Batch 30/365] loss=0.0874, lr=0.0000083, metrics:pearsonr:0.9581
INFO:root:06:01:15 [Epoch 4 Batch 40/365] loss=0.0774, lr=0.0000082, metrics:pearsonr:0.9572
INFO:root:06:01:17 [Epoch 4 Batch 50/365] loss=0.0934, lr=0.0000081, metrics:pearsonr:0.9556
INFO:root:06:01:20 [Epoch 4 Batch 60/365] loss=0.0772, lr=0.0000079, metrics:pearsonr:0.9569
INFO:root:06:01:23 [Epoch 4 Batch 70/365] loss=0.0684, lr=0.0000078, metrics:pearsonr:0.9587
INFO:root:06:01:25 [Epoch 4 Batch 80/365] loss=0.0623, lr=0.0000077, metrics:pearsonr:0.9607
INFO:root:06:01:28 [Epoch 4 Batch 90/365] loss=0.0560, lr=0.0000076, metrics:pearsonr:0.9613
INFO:root:06:01:30 [Epoch 4 Batch 100/365] loss=0.0645, lr=0.0000074, metrics:pearsonr:0.9622
INFO:root:06:01:32 [Epoch 4 Batch 110/365] loss=0.0639, lr=0.0000073, metrics:pearsonr:0.9631
INFO:root:06:01:35 [Epoch 4 Batch 120/365] loss=0.0508, lr=0.0000072, metrics:pearsonr:0.9638
INFO:root:06:01:38 [Epoch 4 Batch 130/365] loss=0.0544, lr=0.0000071, metrics:pearsonr:0.9641
INFO:root:06:01:41 [Epoch 4 Batch 140/365] loss=0.0569, lr=0.0000070, metrics:pearsonr:0.9646
INFO:root:06:01:43 [Epoch 4 Batch 150/365] loss=0.0642, lr=0.0000068, metrics:pearsonr:0.9648
INFO:root:06:01:45 [Epoch 4 Batch 160/365] loss=0.0866, lr=0.0000067, metrics:pearsonr:0.9648
INFO:root:06:01:47 [Epoch 4 Batch 170/365] loss=0.0693, lr=0.0000066, metrics:pearsonr:0.9651
INFO:root:06:01:50 [Epoch 4 Batch 180/365] loss=0.0587, lr=0.0000065, metrics:pearsonr:0.9653
INFO:root:06:01:52 [Epoch 4 Batch 190/365] loss=0.0707, lr=0.0000063, metrics:pearsonr:0.9654
INFO:root:06:01:54 [Epoch 4 Batch 200/365] loss=0.0697, lr=0.0000062, metrics:pearsonr:0.9657
INFO:root:06:01:57 [Epoch 4 Batch 210/365] loss=0.0700, lr=0.0000061, metrics:pearsonr:0.9657
INFO:root:06:01:59 [Epoch 4 Batch 220/365] loss=0.0721, lr=0.0000060, metrics:pearsonr:0.9660
INFO:root:06:02:01 [Epoch 4 Batch 230/365] loss=0.0541, lr=0.0000058, metrics:pearsonr:0.9663
INFO:root:06:02:03 [Epoch 4 Batch 240/365] loss=0.0896, lr=0.0000057, metrics:pearsonr:0.9661
INFO:root:06:02:06 [Epoch 4 Batch 250/365] loss=0.0634, lr=0.0000056, metrics:pearsonr:0.9662
INFO:root:06:02:08 [Epoch 4 Batch 260/365] loss=0.0608, lr=0.0000055, metrics:pearsonr:0.9665
INFO:root:06:02:10 [Epoch 4 Batch 270/365] loss=0.0791, lr=0.0000053, metrics:pearsonr:0.9664
INFO:root:06:02:12 [Epoch 4 Batch 280/365] loss=0.0673, lr=0.0000052, metrics:pearsonr:0.9666
INFO:root:06:02:14 [Epoch 4 Batch 290/365] loss=0.0716, lr=0.0000051, metrics:pearsonr:0.9665
INFO:root:06:02:17 [Epoch 4 Batch 300/365] loss=0.0605, lr=0.0000050, metrics:pearsonr:0.9667
INFO:root:06:02:19 [Epoch 4 Batch 310/365] loss=0.0640, lr=0.0000048, metrics:pearsonr:0.9666
INFO:root:06:02:22 [Epoch 4 Batch 320/365] loss=0.0721, lr=0.0000047, metrics:pearsonr:0.9666
INFO:root:06:02:24 [Epoch 4 Batch 330/365] loss=0.0712, lr=0.0000046, metrics:pearsonr:0.9667
INFO:root:06:02:27 [Epoch 4 Batch 340/365] loss=0.0629, lr=0.0000045, metrics:pearsonr:0.9668
INFO:root:06:02:29 [Epoch 4 Batch 350/365] loss=0.0551, lr=0.0000044, metrics:pearsonr:0.9670
INFO:root:06:02:31 [Epoch 4 Batch 360/365] loss=0.0617, lr=0.0000042, metrics:pearsonr:0.9671
INFO:root:06:02:33 Now we are doing evaluation on dev with gpu(0).
INFO:root:06:02:33 [Batch 10/188] loss=0.1292, metrics:pearsonr:0.9519
INFO:root:06:02:33 [Batch 20/188] loss=0.1589, metrics:pearsonr:0.9529
INFO:root:06:02:34 [Batch 30/188] loss=0.1218, metrics:pearsonr:0.9514
INFO:root:06:02:34 [Batch 40/188] loss=0.1478, metrics:pearsonr:0.9488
INFO:root:06:02:35 [Batch 50/188] loss=0.1662, metrics:pearsonr:0.9448
INFO:root:06:02:35 [Batch 60/188] loss=0.1559, metrics:pearsonr:0.9435
INFO:root:06:02:36 [Batch 70/188] loss=0.2298, metrics:pearsonr:0.9379
INFO:root:06:02:36 [Batch 80/188] loss=0.2609, metrics:pearsonr:0.9319
INFO:root:06:02:37 [Batch 90/188] loss=0.3929, metrics:pearsonr:0.9187
INFO:root:06:02:37 [Batch 100/188] loss=0.3201, metrics:pearsonr:0.9105
INFO:root:06:02:38 [Batch 110/188] loss=0.3374, metrics:pearsonr:0.9019
INFO:root:06:02:38 [Batch 120/188] loss=0.4316, metrics:pearsonr:0.8924
INFO:root:06:02:39 [Batch 130/188] loss=0.2410, metrics:pearsonr:0.8915
INFO:root:06:02:40 [Batch 140/188] loss=0.1354, metrics:pearsonr:0.8948
INFO:root:06:02:40 [Batch 150/188] loss=0.1273, metrics:pearsonr:0.8966
INFO:root:06:02:41 [Batch 160/188] loss=0.1989, metrics:pearsonr:0.8964
INFO:root:06:02:41 [Batch 170/188] loss=0.2369, metrics:pearsonr:0.8948
INFO:root:06:02:42 [Batch 180/188] loss=0.2301, metrics:pearsonr:0.8946
INFO:root:06:02:42 validation metrics:pearsonr:0.8958
INFO:root:06:02:42 Time cost=9.67s, throughput=155.50 samples/s
INFO:root:06:02:58 params saved in: ./output_dir/model_bert_STS-B_3.params
INFO:root:06:02:58 Time cost=112.97s
INFO:root:06:03:01 [Epoch 5 Batch 10/365] loss=0.0554, lr=0.0000040, metrics:pearsonr:0.9768
INFO:root:06:03:04 [Epoch 5 Batch 20/365] loss=0.0494, lr=0.0000039, metrics:pearsonr:0.9764
INFO:root:06:03:07 [Epoch 5 Batch 30/365] loss=0.0438, lr=0.0000038, metrics:pearsonr:0.9761
INFO:root:06:03:10 [Epoch 5 Batch 40/365] loss=0.0436, lr=0.0000037, metrics:pearsonr:0.9762
INFO:root:06:03:12 [Epoch 5 Batch 50/365] loss=0.0536, lr=0.0000035, metrics:pearsonr:0.9761
INFO:root:06:03:14 [Epoch 5 Batch 60/365] loss=0.0411, lr=0.0000034, metrics:pearsonr:0.9773
INFO:root:06:03:17 [Epoch 5 Batch 70/365] loss=0.0367, lr=0.0000033, metrics:pearsonr:0.9775
INFO:root:06:03:20 [Epoch 5 Batch 80/365] loss=0.0439, lr=0.0000032, metrics:pearsonr:0.9780
INFO:root:06:03:22 [Epoch 5 Batch 90/365] loss=0.0468, lr=0.0000031, metrics:pearsonr:0.9782
INFO:root:06:03:24 [Epoch 5 Batch 100/365] loss=0.0366, lr=0.0000029, metrics:pearsonr:0.9787
INFO:root:06:03:27 [Epoch 5 Batch 110/365] loss=0.0462, lr=0.0000028, metrics:pearsonr:0.9785
INFO:root:06:03:30 [Epoch 5 Batch 120/365] loss=0.0421, lr=0.0000027, metrics:pearsonr:0.9783
INFO:root:06:03:33 [Epoch 5 Batch 130/365] loss=0.0464, lr=0.0000026, metrics:pearsonr:0.9783
INFO:root:06:03:35 [Epoch 5 Batch 140/365] loss=0.0413, lr=0.0000024, metrics:pearsonr:0.9785
INFO:root:06:03:38 [Epoch 5 Batch 150/365] loss=0.0469, lr=0.0000023, metrics:pearsonr:0.9785
INFO:root:06:03:40 [Epoch 5 Batch 160/365] loss=0.0511, lr=0.0000022, metrics:pearsonr:0.9782
INFO:root:06:03:42 [Epoch 5 Batch 170/365] loss=0.0530, lr=0.0000021, metrics:pearsonr:0.9781
INFO:root:06:03:45 [Epoch 5 Batch 180/365] loss=0.0375, lr=0.0000019, metrics:pearsonr:0.9783
INFO:root:06:03:48 [Epoch 5 Batch 190/365] loss=0.0340, lr=0.0000018, metrics:pearsonr:0.9783
INFO:root:06:03:50 [Epoch 5 Batch 200/365] loss=0.0403, lr=0.0000017, metrics:pearsonr:0.9786
INFO:root:06:03:52 [Epoch 5 Batch 210/365] loss=0.0472, lr=0.0000016, metrics:pearsonr:0.9786
INFO:root:06:03:55 [Epoch 5 Batch 220/365] loss=0.0480, lr=0.0000014, metrics:pearsonr:0.9785
INFO:root:06:03:57 [Epoch 5 Batch 230/365] loss=0.0467, lr=0.0000013, metrics:pearsonr:0.9785
INFO:root:06:03:59 [Epoch 5 Batch 240/365] loss=0.0371, lr=0.0000012, metrics:pearsonr:0.9786
INFO:root:06:04:02 [Epoch 5 Batch 250/365] loss=0.0453, lr=0.0000011, metrics:pearsonr:0.9785
INFO:root:06:04:04 [Epoch 5 Batch 260/365] loss=0.0598, lr=0.0000010, metrics:pearsonr:0.9784
INFO:root:06:04:06 [Epoch 5 Batch 270/365] loss=0.0473, lr=0.0000008, metrics:pearsonr:0.9785
INFO:root:06:04:09 [Epoch 5 Batch 280/365] loss=0.0561, lr=0.0000007, metrics:pearsonr:0.9783
INFO:root:06:04:11 [Epoch 5 Batch 290/365] loss=0.0490, lr=0.0000006, metrics:pearsonr:0.9782
INFO:root:06:04:13 [Epoch 5 Batch 300/365] loss=0.0551, lr=0.0000005, metrics:pearsonr:0.9781
INFO:root:06:04:15 [Epoch 5 Batch 310/365] loss=0.0443, lr=0.0000003, metrics:pearsonr:0.9783
INFO:root:06:04:18 [Epoch 5 Batch 320/365] loss=0.0417, lr=0.0000002, metrics:pearsonr:0.9783
INFO:root:06:04:20 [Epoch 5 Batch 330/365] loss=0.0458, lr=0.0000001, metrics:pearsonr:0.9783
INFO:root:06:04:21 Finish training step: 1796
INFO:root:06:04:21 Now we are doing evaluation on dev with gpu(0).
INFO:root:06:04:22 [Batch 10/188] loss=0.1247, metrics:pearsonr:0.9528
INFO:root:06:04:22 [Batch 20/188] loss=0.1469, metrics:pearsonr:0.9544
INFO:root:06:04:22 [Batch 30/188] loss=0.1224, metrics:pearsonr:0.9526
INFO:root:06:04:23 [Batch 40/188] loss=0.1513, metrics:pearsonr:0.9497
INFO:root:06:04:23 [Batch 50/188] loss=0.1731, metrics:pearsonr:0.9458
INFO:root:06:04:24 [Batch 60/188] loss=0.1563, metrics:pearsonr:0.9443
INFO:root:06:04:24 [Batch 70/188] loss=0.2515, metrics:pearsonr:0.9381
INFO:root:06:04:25 [Batch 80/188] loss=0.2579, metrics:pearsonr:0.9323
INFO:root:06:04:25 [Batch 90/188] loss=0.3816, metrics:pearsonr:0.9192
INFO:root:06:04:26 [Batch 100/188] loss=0.3074, metrics:pearsonr:0.9114
INFO:root:06:04:27 [Batch 110/188] loss=0.3298, metrics:pearsonr:0.9029
INFO:root:06:04:27 [Batch 120/188] loss=0.4240, metrics:pearsonr:0.8935
INFO:root:06:04:28 [Batch 130/188] loss=0.2396, metrics:pearsonr:0.8925
INFO:root:06:04:29 [Batch 140/188] loss=0.1411, metrics:pearsonr:0.8957
INFO:root:06:04:29 [Batch 150/188] loss=0.1233, metrics:pearsonr:0.8976
INFO:root:06:04:30 [Batch 160/188] loss=0.2034, metrics:pearsonr:0.8975
INFO:root:06:04:30 [Batch 170/188] loss=0.2449, metrics:pearsonr:0.8959
INFO:root:06:04:31 [Batch 180/188] loss=0.2295, metrics:pearsonr:0.8956
INFO:root:06:04:31 validation metrics:pearsonr:0.8967
INFO:root:06:04:31 Time cost=9.74s, throughput=154.47 samples/s
INFO:root:06:04:51 params saved in: ./output_dir/model_bert_STS-B_4.params
INFO:root:06:04:51 Time cost=112.74s
INFO:root:06:05:28 Best model at epoch 4. Validation metrics:pearsonr:0.8967
INFO:root:06:05:28 Now we are doing testing on test with gpu(0).
INFO:root:06:05:38 Time cost=9.40s, throughput=147.24 samples/s
